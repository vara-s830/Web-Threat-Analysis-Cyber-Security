{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c87c0c77",
      "metadata": {
        "id": "c87c0c77"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cdbdefa",
      "metadata": {
        "id": "4cdbdefa"
      },
      "outputs": [],
      "source": [
        "# Load the data into a DataFrame\n",
        "data = pd.read_csv(\"/content/web threat analysis/CloudWatch_Traffic_Web_Attack.csv\")\n",
        "# Display the first few rows of the DataFrame to understand its structure\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230ac979",
      "metadata": {
        "id": "230ac979"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate rows\n",
        "df_unique = data.drop_duplicates()\n",
        "# Convert time-related columns to datetime format\n",
        "df_unique['creation_time'] = pd.to_datetime(df_unique['creation_time'])\n",
        "df_unique['end_time'] = pd.to_datetime(df_unique['end_time'])\n",
        "df_unique['time'] = pd.to_datetime(df_unique['time'])\n",
        "# Standardize text data (example: convert to lower case)\n",
        "df_unique['src_ip_country_code'] = df_unique['src_ip_country_code'].str.upper()  # Ensuring country codes are all upper case\n",
        "# Display changes and current state of the DataFrame\n",
        "print(\"Unique Datasets Information:\")\n",
        "df_unique.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4beb4aa9",
      "metadata": {
        "id": "4beb4aa9"
      },
      "outputs": [],
      "source": [
        "print(\"Top 5 Unique Datasets Information:\")\n",
        "df_unique.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "674a4818",
      "metadata": {
        "id": "674a4818"
      },
      "outputs": [],
      "source": [
        "# Feature engineering: Calculate duration of connection\n",
        "df_unique['duration_seconds'] = (df_unique['end_time'] - df_unique['creation_time']).dt.total_seconds()\n",
        "\n",
        "# Preparing column transformations\n",
        "# StandardScaler for numerical features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df_unique[['bytes_in', 'bytes_out', 'duration_seconds']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d2aae26",
      "metadata": {
        "id": "9d2aae26"
      },
      "outputs": [],
      "source": [
        "# OneHotEncoder for categorical features\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_features = encoder.fit_transform(df_unique[['src_ip_country_code']])\n",
        "\n",
        "# Combining transformed features back into the DataFrame\n",
        "scaled_columns = ['scaled_bytes_in', 'scaled_bytes_out', 'scaled_duration_seconds']\n",
        "encoded_columns = encoder.get_feature_names_out(['src_ip_country_code'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1da718",
      "metadata": {
        "id": "fb1da718"
      },
      "outputs": [],
      "source": [
        "# Convert numpy arrays back to DataFrame\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=scaled_columns, index=df_unique.index)\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoded_columns, index=df_unique.index)\n",
        "\n",
        "# Concatenate all the data back together\n",
        "transformed_df = pd.concat([df_unique, scaled_df, encoded_df], axis=1)\n",
        "# Displaying the transformed data\n",
        "transformed_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90a0b857",
      "metadata": {
        "id": "90a0b857"
      },
      "outputs": [],
      "source": [
        "# Compute correlation matrix for numeric columns only\n",
        "numeric_df = transformed_df.select_dtypes(include=['float64', 'int64'])\n",
        "correlation_matrix_numeric = numeric_df.corr()\n",
        "# Display the correlation matrix\n",
        "correlation_matrix_numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fe7f0f4",
      "metadata": {
        "id": "0fe7f0f4"
      },
      "outputs": [],
      "source": [
        "# Heatmap for the correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix_numeric, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6769386d",
      "metadata": {
        "id": "6769386d"
      },
      "outputs": [],
      "source": [
        "# Stacked Bar Chart for Detection Types by Country\n",
        "# Preparing data for stacked bar chart\n",
        "detection_types_by_country = pd.crosstab(transformed_df['src_ip_country_code'], transformed_df['detection_types'])\n",
        "detection_types_by_country.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
        "plt.title('Detection Types by Country Code')\n",
        "plt.xlabel('Country Code')\n",
        "plt.ylabel('Frequency of Detection Types')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Detection Type')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa2b7cd",
      "metadata": {
        "id": "4aa2b7cd"
      },
      "outputs": [],
      "source": [
        "# Convert 'creation_time' to datetime format\n",
        "data['creation_time'] = pd.to_datetime(data['creation_time'])\n",
        "\n",
        "# Set 'creation_time' as the index\n",
        "data.set_index('creation_time', inplace=True)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(data.index, data['bytes_in'], label='Bytes In', marker='o')\n",
        "plt.plot(data.index, data['bytes_out'], label='Bytes Out', marker='o')\n",
        "plt.title('Web Traffic Analysis Over Time')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Bytes')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e9eb3f",
      "metadata": {
        "id": "01e9eb3f"
      },
      "outputs": [],
      "source": [
        "# Create a graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add edges from source IP to destination IP\n",
        "for idx, row in data.iterrows():\n",
        "    G.add_edge(row['src_ip'], row['dst_ip'])\n",
        "\n",
        "# Draw the network graph\n",
        "plt.figure(figsize=(14, 10))\n",
        "nx.draw_networkx(G, with_labels=True, node_size=20, font_size=8, node_color='skyblue', font_color='darkblue')\n",
        "plt.title('Network Interaction between Source and Destination IPs')\n",
        "plt.axis('off')  # Turn off the axis\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc659a9c",
      "metadata": {
        "id": "fc659a9c"
      },
      "outputs": [],
      "source": [
        "# First, encode this column into binary labels\n",
        "transformed_df['is_suspicious'] = (transformed_df['detection_types'] == 'waf_rule').astype(int)\n",
        "\n",
        "# Features and Labels\n",
        "X = transformed_df[['bytes_in', 'bytes_out', 'scaled_duration_seconds']]  # Numeric features\n",
        "y = transformed_df['is_suspicious']  # Binary labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c879bdb8",
      "metadata": {
        "id": "c879bdb8"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = rf_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc9ea34f",
      "metadata": {
        "id": "cc9ea34f"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification = classification_report(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "191f8d50",
      "metadata": {
        "id": "191f8d50"
      },
      "outputs": [],
      "source": [
        "print(\"Model Accuracy: \",accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a224aa85",
      "metadata": {
        "id": "a224aa85"
      },
      "outputs": [],
      "source": [
        "print(\"Classification Report: \",classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "416fdb71",
      "metadata": {
        "id": "416fdb71"
      },
      "outputs": [],
      "source": [
        "data['is_suspicious'] = (data['detection_types'] == 'waf_rule').astype(int)\n",
        "\n",
        "# Features and labels\n",
        "X = data[['bytes_in', 'bytes_out']].values  # Using only numeric features\n",
        "y = data['is_suspicious'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Neural network model\n",
        "model = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history  = model.fit(X_train_scaled, y_train, epochs=10, batch_size=8, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "677db26c",
      "metadata": {
        "id": "677db26c"
      },
      "outputs": [],
      "source": [
        "# Neural network model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=1, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Plotting the training history\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "830d51a8",
      "metadata": {
        "id": "830d51a8"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
        "X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
        "\n",
        "# Adjusting the network to accommodate the input size\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=1, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=1, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "# Plotting the training history\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae0eacc",
      "metadata": {
        "id": "bae0eacc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
